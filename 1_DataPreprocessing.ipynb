{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_DataPreprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "D8y109fOJb_X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/USD-502-FinalProject/502-Summer2022-FinalProject/main/telecom_customer_churn.csv', sep=',')\n",
        "df_zip = pd.read_csv('https://raw.githubusercontent.com/USD-502-FinalProject/502-Summer2022-FinalProject/main/telecom_zipcode_population.csv', sep=',')\n",
        "\n",
        "\n",
        "# DATA QUALITY ##################################################################\n",
        "#print(df.head(5))\n",
        "#print(df.columns)\n",
        "\n",
        "\n",
        "# Set flags here for output #####################################################\n",
        "z_correlation_matrix = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################################\n",
        "# Assign binary values for 'Customer Status' target variable\n",
        "# Loop through each row of dataframe, assigning value for 'Customer Status'\n",
        "# as either 0 or 1\n",
        "for i, row in df.iterrows():\n",
        "\n",
        "    val = 0  # default Stayed\n",
        "\n",
        "    # Joined or Stayed\n",
        "    if row['Customer Status'] == 'Stayed' or row['Customer Status'] == 'Joined':\n",
        "        val = 0\n",
        "    else:  # Churned\n",
        "        val = 1\n",
        "\n",
        "    df.at[i,'Customer Status'] = val\n",
        "\n",
        "\n",
        "# Convert 'Customer Status' column into int/numeric\n",
        "df['Customer Status'] = pd.to_numeric(df['Customer Status'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TA7PB4PB8ljf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FEATURE SCALING - STANDARDIZING THE COLUMN VALUES - NUMERIC ONLY ############\n",
        "# NOT NEEDED for our binary classifier models but we keep it here commented out\n",
        "# in case the need arises\n",
        "# Logistic Regression, Decision Tree, Random Forest, Naive Bayes, SVM\n",
        "# are not sensitive to the magnitude of variables, so feature scaling not\n",
        "# required\n",
        "# Only required if the logistic regression is regularized in which case\n",
        "# the input needs to be normalized\n",
        "#df_numeric = df._get_numeric_data()\n",
        "#Z = (data2-data2.mean())/data2.std()"
      ],
      "metadata": {
        "id": "Yz0mVIhh9E8g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################################\n",
        "# NORMALIZE THE NUMERIC COLUMNS\n",
        "# Only necessary for models like KNN, not necessary for logistic regression\n",
        "################################################################################################\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# normalize all the numeric columns in df\n",
        "df_numeric_columns = df._get_numeric_data()\n",
        "\n",
        "# remove Zip Code, Longitude, Latitude, normalizing these makes no sense\n",
        "df_numeric_columns = df_numeric_columns.drop(['Zip Code', 'Longitude', 'Latitude', 'Customer Status'], axis=1)\n",
        "\n",
        "# Perform the transformation on the data so that it is scaled to range 0-1\n",
        "df_scaled = scaler.fit_transform(df_numeric_columns)\n",
        "\n",
        "# create a new dataframe containing the normalized values and corresponding column names\n",
        "#norm = pd.DataFrame(df_scaled, columns = df._get_numeric_data().columns)\n",
        "norm = pd.DataFrame(df_scaled, columns = df_numeric_columns.columns)\n",
        "\n",
        "norm.head(2)\n",
        "\n",
        "# Takes df_master dataframe and replaces the normalized columns from norm_df\n",
        "def replace_norms(df_master, df_norm):\n",
        "    cols = df_norm.columns\n",
        "    for col in cols:\n",
        "        df_master[col] = df_norm[col]\n",
        "\n",
        "replace_norms(df, norm)\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "PMXzjnAK9TlH",
        "outputId": "2f663320-7960-4d6d-ef35-25b1360e48a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Customer ID  Gender       Age Married  Number of Dependents          City  \\\n",
              "0  0002-ORFBO  Female  0.295082     Yes                   0.0  Frazier Park   \n",
              "1  0003-MKNFE    Male  0.442623      No                   0.0      Glendale   \n",
              "\n",
              "   Zip Code   Latitude   Longitude  Number of Referrals  ...  Payment Method  \\\n",
              "0     93225  34.827662 -118.999073             0.181818  ...     Credit Card   \n",
              "1     91206  34.162515 -118.203869             0.000000  ...     Credit Card   \n",
              "\n",
              "  Monthly Charge Total Charges  Total Refunds Total Extra Data Charges  \\\n",
              "0       0.587184      0.066294       0.000000                 0.000000   \n",
              "1       0.046602      0.060420       0.769833                 0.066667   \n",
              "\n",
              "  Total Long Distance Charges Total Revenue  Customer Status Churn Category  \\\n",
              "0                    0.107024      0.079733                0            NaN   \n",
              "1                    0.026989      0.049249                0            NaN   \n",
              "\n",
              "  Churn Reason  \n",
              "0          NaN  \n",
              "1          NaN  \n",
              "\n",
              "[2 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a9bb15c-85ce-44a7-8f13-d7d0992d10e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customer ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Married</th>\n",
              "      <th>Number of Dependents</th>\n",
              "      <th>City</th>\n",
              "      <th>Zip Code</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Number of Referrals</th>\n",
              "      <th>...</th>\n",
              "      <th>Payment Method</th>\n",
              "      <th>Monthly Charge</th>\n",
              "      <th>Total Charges</th>\n",
              "      <th>Total Refunds</th>\n",
              "      <th>Total Extra Data Charges</th>\n",
              "      <th>Total Long Distance Charges</th>\n",
              "      <th>Total Revenue</th>\n",
              "      <th>Customer Status</th>\n",
              "      <th>Churn Category</th>\n",
              "      <th>Churn Reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002-ORFBO</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.295082</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Frazier Park</td>\n",
              "      <td>93225</td>\n",
              "      <td>34.827662</td>\n",
              "      <td>-118.999073</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>...</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>0.587184</td>\n",
              "      <td>0.066294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.107024</td>\n",
              "      <td>0.079733</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0003-MKNFE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.442623</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Glendale</td>\n",
              "      <td>91206</td>\n",
              "      <td>34.162515</td>\n",
              "      <td>-118.203869</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>0.046602</td>\n",
              "      <td>0.060420</td>\n",
              "      <td>0.769833</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.026989</td>\n",
              "      <td>0.049249</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a9bb15c-85ce-44a7-8f13-d7d0992d10e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a9bb15c-85ce-44a7-8f13-d7d0992d10e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a9bb15c-85ce-44a7-8f13-d7d0992d10e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################################\n",
        "# ONE HOT ENCODING\n",
        "# One method used to handle the categorical columns and expands them out into binary form\n",
        "# Disadvantage: Creates a lot of additional columns\n",
        "# Use for non-ordinal categorical values and when there are not so many categorical values per column\n",
        "# Typically use PCA reduction afterwards because it produces too many columns\n",
        "# https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/\n",
        "# https://datascience.stackexchange.com/questions/9443/when-to-use-one-hot-encoding-vs-labelencoder-vs-dictvectorizor\n",
        "# https://www.ritchieng.com/machinelearning-one-hot-encoding/\n",
        "# https://stats.stackexchange.com/questions/48360/is-standardization-needed-before-fitting-logistic-regression#:~:text=You%20don't%20need%20to,helps%20interpretability%2C%20and%20rarely%20hurts.\n",
        "#\n",
        "# Issues to check on:\n",
        "# Does zip code or city have any correlation to Churn ?\n",
        "# Correlation matrix shows that City has very little correlation with Churn,\n",
        "# so for now we don't hotencode.  Zip Code with city-data.com may provide\n",
        "# additional insight into the demographic data relating to a zipcode but\n",
        "# that is extra if we have time.\n",
        "################################################################################################\n",
        "\n",
        "# Select all categorical value columns, they will be of type object\n",
        "df_cat_cols = pd.DataFrame(df.dtypes[df.dtypes == 'object'])\n",
        "\n",
        "# fill any missing values with \"other\" and then drop these columns after the hot encoding\n",
        "df_cat_cols = df_cat_cols.fillna(\"other\", axis=\"index\")\n",
        "\n",
        "cat_cols = np.array(df_cat_cols.index)\n",
        "\n",
        "# We do not need to onehotencode Customer Status because this is the target\n",
        "# variable.  Customer ID is irrelevant.\n",
        "# Not sure what to do about City right now, it increases the dimensionality\n",
        "# by too much.  We can decide what do with it later after I get the model\n",
        "# working.\n",
        "#cat_cols = np.array(pd.DataFrame(df.dtypes[df.dtypes == 'object']).index)\n",
        "#cat_cols = np.delete(cat_cols, 20) # remove the target variable 'Customer Status'\n",
        "cat_cols = np.delete(cat_cols, 0)  # remove Customer ID\n",
        "cat_cols = np.delete(cat_cols, 2)  # remove City - no correlation from matrix\n",
        "#cat_cols = df.select_dtypes(include=[object])\n",
        "\n",
        "\n",
        "# Drop the first feature in the category\n",
        "#ohe = OneHotEncoder(drop = 'first').fit(df[cat_cols])\n",
        "ohe = OneHotEncoder().fit(df[cat_cols])\n",
        "# why don't you just get_dummies()?\n",
        "\n",
        "# perform the one hot encoding on the categorical columns\n",
        "# assign it to an array type\n",
        "# We end up with 8200 columns....too big!\n",
        "ohe_array = ohe.fit_transform(df[cat_cols]).toarray()\n",
        "\n",
        "# Take the array of one hot encoded columns and create a dataframe out of it\n",
        "ohe_df = pd.DataFrame(ohe_array, index = df.index, columns = ohe.get_feature_names(cat_cols))\n",
        "\n",
        "# Drop the categorical columns from the original dataframe\n",
        "df_drop_col = df.drop(columns = cat_cols)\n",
        "\n",
        "# Merge the one hot encoded columns and the dataframe containing the dropped columns\n",
        "df_ohed = pd.concat([df_drop_col, ohe_df], axis = 1)\n",
        "df_ohed.columns\n",
        "print(df_ohed.head(2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGjvh9HF9XHS",
        "outputId": "e71b01c7-e5b0-4077-d5b0-03c1c6a8be40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Customer ID       Age  Number of Dependents          City  Zip Code  \\\n",
            "0  0002-ORFBO  0.295082                   0.0  Frazier Park     93225   \n",
            "1  0003-MKNFE  0.442623                   0.0      Glendale     91206   \n",
            "\n",
            "    Latitude   Longitude  Number of Referrals  Tenure in Months  \\\n",
            "0  34.827662 -118.999073             0.181818          0.112676   \n",
            "1  34.162515 -118.203869             0.000000          0.112676   \n",
            "\n",
            "   Avg Monthly Long Distance Charges  ...  \\\n",
            "0                           0.844835  ...   \n",
            "1                           0.197632  ...   \n",
            "\n",
            "   Churn Reason_Limited range of services  Churn Reason_Long distance charges  \\\n",
            "0                                     0.0                                 0.0   \n",
            "1                                     0.0                                 0.0   \n",
            "\n",
            "   Churn Reason_Moved  Churn Reason_Network reliability  \\\n",
            "0                 0.0                               0.0   \n",
            "1                 0.0                               0.0   \n",
            "\n",
            "   Churn Reason_Poor expertise of online support  \\\n",
            "0                                            0.0   \n",
            "1                                            0.0   \n",
            "\n",
            "   Churn Reason_Poor expertise of phone support  Churn Reason_Price too high  \\\n",
            "0                                           0.0                          0.0   \n",
            "1                                           0.0                          0.0   \n",
            "\n",
            "   Churn Reason_Product dissatisfaction  Churn Reason_Service dissatisfaction  \\\n",
            "0                                   0.0                                   0.0   \n",
            "1                                   0.0                                   0.0   \n",
            "\n",
            "   Churn Reason_nan  \n",
            "0               1.0  \n",
            "1               1.0  \n",
            "\n",
            "[2 rows x 98 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################################\n",
        "# PCA reduction to reduce the number of columns from 8200 down to something more realistic\n",
        "# to feed to the logistic regression model\n",
        "################################################################################################\n",
        "'''\n",
        "from sklearn import datasets  # to retrieve the iris Dataset\n",
        "import pandas as pd  # to load the dataframe\n",
        "from sklearn.preprocessing import StandardScaler  # to standardize the features\n",
        "from sklearn.decomposition import PCA  # to apply PCA\n",
        "import seaborn as sns  # to plot the heat maps\n",
        "\n",
        "\n",
        "#Standardize the features\n",
        "#Create an object of StandardScaler which is present in sklearn.preprocessing\n",
        "scalar = StandardScaler()\n",
        "scaled_data = pd.DataFrame(scalar.fit_transform(df.select_dtypes(include=[np.number]))) #scaling the data\n",
        "scaled_data\n",
        "\n",
        "# clean up NaN\n",
        "# drop all rows containing NaN\n",
        "# https://sparkbyexamples.com/pandas/pandas-drop-rows-with-nan-values-in-dataframe/#:~:text=By%20using%20dropna()%20method,you%20should%20use%20inplace%3DTrue%20.\n",
        "scaled_data = scaled_data.dropna()\n",
        "\n",
        "\n",
        "\n",
        "#Check the Co-relation between features without PCA\n",
        "sns.heatmap(scaled_data.corr())\n",
        "\n",
        "\n",
        "#Applying PCA\n",
        "#Taking no. of Principal Components as 3\n",
        "pca = PCA(n_components = 3)\n",
        "pca.fit(scaled_data)\n",
        "data_pca = pca.transform(scaled_data)\n",
        "data_pca = pd.DataFrame(data_pca,columns=['PC1','PC2','PC3'])\n",
        "data_pca.head()\n",
        "\n",
        "\n",
        "\n",
        "#Checking Co-relation between features after PCA\n",
        "sns.heatmap(data_pca.corr())\n",
        "'''\n"
      ],
      "metadata": {
        "id": "OuQnREVrA0Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################################\n",
        "# CORRELATION MATRIX to explore relationships between variables\n",
        "# We want to see the relationship of categorical variables against the 'Customer Status' (churn) target variable\n",
        "# https://github.com/shakedzy/dython/blob/master/docs/getting_started/examples.md\n",
        "# 0 = no association, 1 = associated\n",
        "################################################################################################\n",
        "# Categorical Data\n",
        "'''\n",
        "if z_correlation_matrix == True:\n",
        "    #plt.rcParams.update({'font.size': 8})\n",
        "    corr_df_cat = df_ohed.drop(columns=['Customer ID', 'Age', 'City', 'Zip Code', 'Latitude', 'Longitude'])\n",
        "    #corr_df_cat = df[['Gender', 'Married','City', 'Offer', 'Phone Service', 'Multiple Lines', 'Internet Type', 'Online Security', 'Online Backup', 'Device Protection Plan', 'Premium Tech Support', 'Streaming TV', 'Streaming Movies', 'Unlimited Data', 'Contract', 'Paperless Billing', 'Payment Method', 'Churn Category', 'Customer Status']]\n",
        "    #nominal.associations(corr_df_cat, nominal_columns = 'auto', figsize=(15, 15), annot =True)\n",
        "\n",
        "    # Your data should be a pandas dataframe for this example\n",
        "    corr_matrix = corr_df_cat.corr()\n",
        "    matrix = corr_matrix[\"Customer Status\"].sort_values(ascending=False)\n",
        "    # why does the above turn Customer Status into nan?\n",
        "    #matrix = matrix.unstack()\n",
        "    matrix = matrix[abs(matrix) >= 0]\n",
        "\n",
        "    # sideways bar chart of anything\n",
        "\n",
        "    corr_matrix.to_csv('correlation_matrix.csv')\n",
        "    print(matrix.head(25))\n",
        "'''"
      ],
      "metadata": {
        "id": "-XdskQq6ELba"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
